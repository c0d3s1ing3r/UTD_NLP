# Overview of NLP

A. Natural Language Processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.

B. AI is related to NLP in that it is a branch of computer science that aims to create intelligent machines. NLP is a subfield of AI that focuses on the interactions between computers and human (natural) languages.

C. There is some difference between natural language understanding and natural language generation. Natural language understanding is the ability of a computer program to derive meaning from human or natural language input, while natural language generation is the ability to produce human-like text from data or structured information.

D. Some modern applications of NLP include:

    * Chatbots, which simulate conversation with humans in order to provide information or perform tasks.
    * Machine translation, which translates text from one language to another.
    * Information retrieval, which searches for documents containing specified information.
    * Question answering, which answers questions posed in natural language.

E. There are three main approaches to NLP:

  1. Rule-based approaches, which involve the creation of hand-written rules that a computer program can follow to perform a task. These approaches are often used in situations where large amounts of training data are not available. However, they are not very robust, and are often difficult to scale to large datasets. While they are still used in some applications, they are not as popular as they once were.
     
  2. Statistical approaches, which involve the creation of statistical models that a computer program can use to perform a task. The approaches use probabilistic models to predict the likelihood of a sequence of words occurring in a particular order. This approach is very similar to traditional machine learning approaches, but importantly, excludes Neural Networks as a statistical modeling approach.

  3. Neural Network approaches, which involve the creation of artificial neural networks that a computer program can use to perform a task. These approaches are very similar to statistical approaches, but they are more robust and scalable. They are also more accurate than statistical approaches, and are therefore more popular than statistical approaches. These rely on huge amounts of data to train the model, and the usual feature engineering and other techniques that are popular in the statistical appraoches is notably absent.

F. I view natural language processing as one of the more interesting fields of ML. Besides the fact that it has become one of the most popularized fields, it also has a large body of modern research behind it. I'm interested in it both from the perspective of its personal and professional applications. For both though, what makes me most interested is the ability for models to take actions in systems as agents themselves. From a professional standpoint, this could be as simple as an automated agent collecting information from a customer and giving a refund. From a personal standpoint, this could be as broad as an AI storyteller in a virtual experience, with the ability to take actions and make decisions based on the information it has collected. The ability to have a system that can take actions and make decisions based on the information it has collected is one of the most interesting aspects of NLP to me.