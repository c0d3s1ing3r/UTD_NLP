{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification wth Keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will build a text classification model using Keras. We will use the <u>Sentiment Analysis</u> Data Set from [UCI](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). We will create sequential, CNN, and RNN models to predict the sentiment of a given text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers, models\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in each file\n",
    "# data appears to be tab delimited\n",
    "\n",
    "amazon = pd.read_csv('amazon_cells_labelled.txt', delimiter='\\t', header=None)\n",
    "imdb = pd.read_csv('imdb_labelled.txt', delimiter='\\t', header=None)\n",
    "yelp = pd.read_csv('yelp_labelled.txt', delimiter='\\t', header=None)\n",
    "\n",
    "# combine all data into one dataframe\n",
    "df = pd.concat([amazon, imdb, yelp])\n",
    "df.columns = ['text', 'label']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  (2180, 2)\n",
      "test data size:  (568, 2)\n"
     ]
    }
   ],
   "source": [
    "# split df into train and test\n",
    "i = np.random.rand(len(df)) < 0.8\n",
    "train = df[i]\n",
    "test = df[~i]\n",
    "print(\"train data size: \", train.shape)\n",
    "print(\"test data size: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (2180, 4698) (2180,)\n",
      "test shapes: (568, 4698) (568,)\n",
      "test first five labels: [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "X_train = tokenizer.texts_to_matrix(train['text'])\n",
    "X_test = tokenizer.texts_to_matrix(test['text'])\n",
    "\n",
    "\n",
    "# use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train['label'])\n",
    "y_train = encoder.transform(train['label'])\n",
    "y_test = encoder.transform(test['label'])\n",
    "\n",
    "# check shape\n",
    "print(\"train shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"test shapes:\", X_test.shape, y_test.shape)\n",
    "print(\"test first five labels:\", y_test[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               2405888   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,406,401\n",
      "Trainable params: 2,406,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(512, input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6720 - accuracy: 0.6126 - val_loss: 0.6621 - val_accuracy: 0.5963\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5516 - accuracy: 0.8486 - val_loss: 0.5920 - val_accuracy: 0.7431\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4191 - accuracy: 0.9072 - val_loss: 0.5142 - val_accuracy: 0.7982\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3022 - accuracy: 0.9378 - val_loss: 0.4658 - val_accuracy: 0.8028\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2101 - accuracy: 0.9613 - val_loss: 0.4437 - val_accuracy: 0.8119\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1493 - accuracy: 0.9725 - val_loss: 0.4034 - val_accuracy: 0.8165\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1118 - accuracy: 0.9827 - val_loss: 0.4362 - val_accuracy: 0.8119\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0843 - accuracy: 0.9898 - val_loss: 0.4062 - val_accuracy: 0.8349\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0671 - accuracy: 0.9918 - val_loss: 0.4383 - val_accuracy: 0.8303\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0522 - accuracy: 0.9954 - val_loss: 0.4276 - val_accuracy: 0.8349\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8310\n",
      "Accuracy:  0.8309859037399292\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=100, verbose=1)\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4387046992778778, 0.8309859037399292]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "Accuracy:  0.8309859154929577\n",
      "Precision:  0.8137254901960784\n",
      "Recall:  0.8645833333333334\n",
      "F1:  0.8383838383838385\n",
      "Confusion Matrix: \n",
      " [[223  57]\n",
      " [ 39 249]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       280\n",
      "           1       0.81      0.86      0.84       288\n",
      "\n",
      "    accuracy                           0.83       568\n",
      "   macro avg       0.83      0.83      0.83       568\n",
      "weighted avg       0.83      0.83      0.83       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int).flatten()\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 4694, 256)         1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1173, 256)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1173, 256)         0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1169, 128)         163968    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 292, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 292, 128)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 37376)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 37377     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,881\n",
      "Trainable params: 202,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv1D(256, 5, padding='valid', activation='relu', strides=1, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(layers.MaxPooling1D(pool_size=4))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, 5, padding='valid', activation='relu', strides=1))\n",
    "model.add(layers.MaxPooling1D(pool_size=4))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.6877 - accuracy: 0.5449 - val_loss: 0.7130 - val_accuracy: 0.3899\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 24s 1s/step - loss: 0.6488 - accuracy: 0.6335 - val_loss: 0.7028 - val_accuracy: 0.5413\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.6054 - accuracy: 0.6855 - val_loss: 0.6976 - val_accuracy: 0.5550\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.5774 - accuracy: 0.7018 - val_loss: 0.6741 - val_accuracy: 0.5872\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.5416 - accuracy: 0.7217 - val_loss: 0.7265 - val_accuracy: 0.5780\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.5173 - accuracy: 0.7457 - val_loss: 0.7285 - val_accuracy: 0.5872\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.5015 - accuracy: 0.7513 - val_loss: 0.7145 - val_accuracy: 0.6239\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.4800 - accuracy: 0.7722 - val_loss: 0.6742 - val_accuracy: 0.6514\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.4532 - accuracy: 0.7742 - val_loss: 0.6742 - val_accuracy: 0.6468\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.4338 - accuracy: 0.7946 - val_loss: 0.7276 - val_accuracy: 0.6606\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.4223 - accuracy: 0.8012 - val_loss: 0.7193 - val_accuracy: 0.6743\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 27s 2s/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.7798 - val_accuracy: 0.6651\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 27s 2s/step - loss: 0.3781 - accuracy: 0.8257 - val_loss: 0.7279 - val_accuracy: 0.6560\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 25s 2s/step - loss: 0.3757 - accuracy: 0.8298 - val_loss: 0.7400 - val_accuracy: 0.6651\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.3382 - accuracy: 0.8486 - val_loss: 0.7069 - val_accuracy: 0.6606\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.3381 - accuracy: 0.8542 - val_loss: 0.6825 - val_accuracy: 0.6881\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.3167 - accuracy: 0.8675 - val_loss: 0.7043 - val_accuracy: 0.6881\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.3118 - accuracy: 0.8563 - val_loss: 0.7326 - val_accuracy: 0.6972\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.2884 - accuracy: 0.8761 - val_loss: 0.7229 - val_accuracy: 0.7202\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 26s 2s/step - loss: 0.2971 - accuracy: 0.8736 - val_loss: 0.7305 - val_accuracy: 0.6881\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 107ms/step\n",
      "Accuracy:  0.6883802816901409\n",
      "Precision:  0.7126436781609196\n",
      "Recall:  0.6458333333333334\n",
      "F1:  0.6775956284153006\n",
      "Confusion Matrix: \n",
      " [[205  75]\n",
      " [102 186]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       280\n",
      "           1       0.71      0.65      0.68       288\n",
      "\n",
      "    accuracy                           0.69       568\n",
      "   macro avg       0.69      0.69      0.69       568\n",
      "weighted avg       0.69      0.69      0.69       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int).flatten()\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess slightly differently for an RNN model\n",
    "\n",
    "# tokenize text\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train['text'])\n",
    "X_test = tokenizer.texts_to_sequences(test['text'])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 64)           300672    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,058\n",
      "Trainable params: 309,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 64, input_length=maxlen))\n",
    "model.add(layers.SimpleRNN(64))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.8792 - val_accuracy: 0.6849\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.8598 - val_accuracy: 0.6866\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.9091 - val_accuracy: 0.6866\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.6954\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.9252 - val_accuracy: 0.6813\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.6989\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.6884\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.6884\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.6866\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.6849\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.6866\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.6866\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9810 - val_accuracy: 0.6919\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.6954\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 8.9357e-04 - accuracy: 1.0000 - val_loss: 0.9923 - val_accuracy: 0.6849\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 8.2664e-04 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.6989\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 7.6324e-04 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.6937\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 7.0169e-04 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.6972\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 6.5718e-04 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.6972\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 6.1522e-04 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.6937\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train, epochs=20, batch_size=128, validation_data=(X_test_pad, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step\n",
      "Accuracy:  0.6936619718309859\n",
      "Precision:  0.6815286624203821\n",
      "Recall:  0.7430555555555556\n",
      "F1:  0.7109634551495018\n",
      "Confusion Matrix: \n",
      " [[180 100]\n",
      " [ 74 214]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67       280\n",
      "           1       0.68      0.74      0.71       288\n",
      "\n",
      "    accuracy                           0.69       568\n",
      "   macro avg       0.70      0.69      0.69       568\n",
      "weighted avg       0.69      0.69      0.69       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "y_pred = model.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4533960412f148fa378cbcde7564d079cd30a0b0b92f06b3b6550f76c759543d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
